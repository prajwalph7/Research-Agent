import os
from datetime import datetime
from IPython.display import display, HTML
import json

class ResearchAgent:
    def __init__(self, use_api=True):
        self.use_api = use_api
        self.model = None
        
        if use_api:
            try:
                from ibm_watsonx_ai.foundation_models import ModelInference
                from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams
                from ibm_watsonx_ai import Credentials
                
                # Initialize IBM Watsonx credentials
                self.creds = Credentials(
                    api_key="MXFEu4LLh4CACsmodgzXuhGfPRsGTRm2FJ5FYW2Rl6Z0",
                    url="https://eu-gb.ml.cloud.ibm.com"
                )
                
                # Initialize Granite model
                self.model = ModelInference(
                    model_id="ibm/granite-13b-instruct-v2",
                    credentials=self.creds,
                    project_id="a168522a-7d85-42fd-bbf2-2fc1655c111b",
                    params={
                        GenParams.DECODING_METHOD: "greedy",
                        GenParams.MAX_NEW_TOKENS: 1000,
                        GenParams.TEMPERATURE: 0.7,
                        GenParams.REPETITION_PENALTY: 1.2
                    }
                )
            except Exception as e:
                print(f"API initialization failed, using local mode: {str(e)}")
                self.use_api = False
        else:
            self.use_api = False
    
    def get_current_time(self):
        return datetime.now().strftime("%I:%M %p")
    
    def format_response(self, user_input, agent_response, preview_data=None):
        """Format the response with optional preview"""
        time_str = self.get_current_time()
        
        response_html = f"""
        <div style='font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto;'>
            <div style='color: #666; font-size: 14px; margin-bottom: 5px;'>{time_str}</div>
            <div style='color: #333; font-weight: bold; margin-bottom: 10px;'>You: {user_input}</div>
            
            <hr style='border: 0; border-top: 1px solid #eee; margin: 15px 0;'>
            
            <div style='color: #666; font-size: 14px;'>{time_str}</div>
            <div style='color: #2b5876; font-weight: bold; margin-bottom: 10px;'>Research Agent</div>
        """
        
        if preview_data:
            response_html += """
            <div style='background-color: #f8f9fa; border-radius: 8px; padding: 15px; margin-bottom: 15px;'>
                <div style='font-weight: bold; margin-bottom: 10px;'>Search Preview:</div>
            """
            
            for i, item in enumerate(preview_data, 1):
                response_html += f"""
                <div style='margin-bottom: 15px;'>
                    <div style='font-weight: bold;'>{i}. {item['title']}</div>
                    <div style='color: #555; font-size: 14px; margin: 5px 0;'>{item['summary']}</div>
                    <div style='display: flex; justify-content: space-between; font-size: 13px;'>
                        <span style='color: #666;'>Source: {item['source']}</span>
                        <span style='color: #1a73e8; cursor: pointer;'>Read more</span>
                    </div>
                </div>
                """
            
            response_html += "</div>"
        
        response_html += f"""
            <div style='line-height: 1.5;'>{agent_response}</div>
            
            <hr style='border: 0; border-top: 1px solid #eee; margin: 15px 0;'>
            
            <div style='color: #999; font-size: 14px;'>Type something...</div>
        </div>
        """
        
        return response_html
    
    def generate_local_response(self, query):
        """Generate sample responses when API is not available"""
        sample_data = {
            "AI in healthcare": {
                "preview": [
                    {
                        "title": "AI for Early Cancer Detection",
                        "summary": "Machine learning models can now detect early signs of cancer with 92% accuracy from medical scans.",
                        "source": "Nature Medicine",
                        "year": 2024
                    },
                    {
                        "title": "Generative AI in Drug Discovery",
                        "summary": "New AI models can generate potential drug compounds 100x faster than traditional methods.",
                        "source": "Science Journal",
                        "year": 2023
                    }
                ],
                "response": "Recent advances in AI for healthcare show promising results in diagnostics and drug discovery. Key areas of progress include..."
            },
            "Climate change AI solutions": {
                "preview": [
                    {
                        "title": "AI for Carbon Capture Optimization",
                        "summary": "Neural networks are being used to optimize carbon capture systems, improving efficiency by 30%.",
                        "source": "Environmental Science & Technology",
                        "year": 2024
                    }
                ],
                "response": "AI applications in climate science are helping optimize renewable energy systems and improve climate modeling accuracy..."
            }
        }
        
        if query in sample_data:
            return sample_data[query]["response"], sample_data[query]["preview"]
        else:
            default_response = f"Here are some key findings about {query} based on recent research..."
            default_preview = [{
                "title": f"Recent Advances in {query}",
                "summary": "New research shows significant progress in this field with multiple breakthroughs.",
                "source": "Various Journals",
                "year": 2024
            }]
            return default_response, default_preview
    
    def search_literature(self, query):
        """Search for academic literature with preview"""
        if self.use_api and self.model:
            try:
                # First get structured preview data
                preview_prompt = f"""
                For the query "{query}", generate 5-7 recent (2023-2025) academic resources.
                Return ONLY a JSON array with items containing:
                - title (string)
                - summary (2-3 sentences)
                - source (journal/conference name)
                - year (publication year)
                """
                
                preview_response = self.model.generate_text(preview_prompt)
                preview_data = json.loads(preview_response)
                
                # Then generate the full response
                response_prompt = f"""
                Based on these resources about {query}:
                {json.dumps(preview_data, indent=2)}
                
                Generate a comprehensive response that:
                1. Introduces the topic
                2. Highlights key findings from the resources
                3. Identifies research gaps
                4. Suggests future directions
                """
                
                full_response = self.model.generate_text(response_prompt)
                
                return self.format_response(
                    f"Show me recent research on {query}",
                    full_response,
                    preview_data
                )
                
            except Exception as e:
                print(f"API call failed, using local data: {str(e)}")
                full_response, preview_data = self.generate_local_response(query)
                return self.format_response(
                    f"Show me recent research on {query}",
                    full_response,
                    preview_data
                )
        else:
            full_response, preview_data = self.generate_local_response(query)
            return self.format_response(
                f"Show me recent research on {query}",
                full_response,
                preview_data
            )

# Example usage in Jupyter Notebook
if __name__ == "__main__":
    # Try with API first, falls back to local if fails
    agent = ResearchAgent(use_api=True)
    
    # Display a sample search with preview
    display(HTML(agent.search_literature("AI in healthcare")))
    display(HTML(agent.search_literature("Climate change AI solutions")))